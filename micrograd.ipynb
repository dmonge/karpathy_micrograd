{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e080ac35-c147-4bd9-8ebc-61da89223d45",
   "metadata": {},
   "source": [
    "# Micrograd evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e883e-a53a-4099-8b60-715c563866c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import random\n",
    "\n",
    "from micrograd.core import Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26b593a-93b6-4a51-ba3d-8f0aff82edec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_graph(root: Value):\n",
    "    \"\"\"Build a graph with GraphViz\"\"\"\n",
    "    visited = set()    \n",
    "    _get_value_str = lambda v: f'{v.name} | data={v.data:0.3f} | grad={v.grad:0.3f}'\n",
    "\n",
    "    def _expand_value(value):\n",
    "        \"\"\"Expand children\"\"\"\n",
    "        if value in visited:\n",
    "            return\n",
    "        visited.add(value)\n",
    "        \n",
    "        if value.operator:\n",
    "            # connect operator node\n",
    "            operator_id = f'{id(value)}_{value.operator}'\n",
    "            graph.node(operator_id, label=value.operator)\n",
    "            graph.edge(operator_id, str(id(value)))\n",
    "            # connect children\n",
    "            for child in value.children:\n",
    "                child_id = str(id(child))\n",
    "                graph.node(child_id, label=_get_value_str(child), shape='record')  # child nodes\n",
    "                graph.edge(child_id, operator_id)\n",
    "                _expand_value(child)\n",
    "            \n",
    "    # process\n",
    "    graph = graphviz.Digraph(format='svg', graph_attr={'rankdir': 'LR'})\n",
    "    graph.node(str(id(root)), _get_value_str(root), shape='record')\n",
    "    _expand_value(root)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d195127-9489-4f17-a0c1-a52ff8ed30bd",
   "metadata": {},
   "source": [
    "### Create a computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c539dc-1890-4e42-8934-dd4e02d769d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = Value(3, name='a')\n",
    "b = Value(2, name='b')\n",
    "c = a * b\n",
    "d = c + 1\n",
    "c.name = 'c'\n",
    "d.name = 'd'\n",
    "\n",
    "build_graph(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4719dc9-99a8-4b35-8b5a-29b4e1de8336",
   "metadata": {},
   "source": [
    "### Compare numerical and approximate derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287591f-6bc8-47d0-8d9f-6494a94f27bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_deriv():\n",
    "    # manual deriv\n",
    "    a = Value(3, name='a')\n",
    "    b = Value(2, name='b')\n",
    "    c = a * b\n",
    "    d = c + 1\n",
    "    c.name = 'c'\n",
    "    d.name = 'd'\n",
    "    L1 = d.data\n",
    "    \n",
    "    h = 0.001  # step\n",
    "    a = Value(3 + h, name='a')  # adding step to a\n",
    "    b = Value(2, name='b')\n",
    "    c = a * b\n",
    "    d = c + 1\n",
    "    c.name = 'c'\n",
    "    d.name = 'd'\n",
    "    L2 = d.data\n",
    "    \n",
    "    print('Approximate derivative dL/da:', (L2-L1) / h)\n",
    "    \n",
    "    # numerical deriv\n",
    "    d.zero_grad()\n",
    "    d.backward()\n",
    "    \n",
    "    print('Numerical derivative dL/da:', a.grad)\n",
    "\n",
    "test_deriv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55835181-23f1-4ab0-93ef-6d5c52902904",
   "metadata": {},
   "source": [
    "### Simulate data updates and gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c5078-7526-4b1f-8d74-84564870f8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = Value(3, name='a')\n",
    "b = Value(-2, name='b')\n",
    "c = a * b; c.name = 'c'\n",
    "d = c + 1; d.name = 'd'\n",
    "e = d * b ; e.name = 'e'\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd5696-c28a-4eac-a736-e79687da0a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "build_graph(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31100c28-60fe-4b87-8fe9-9bc48f936b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('original data on e:', e.data)\n",
    "\n",
    "# weight update\n",
    "a.data += 0.01 * a.grad\n",
    "b.data += 0.01 * b.grad\n",
    "\n",
    "# \"forward pass\"\n",
    "c = a * b; c.name = 'c'\n",
    "d = c + 1; d.name = 'd'\n",
    "e = d * b ; e.name = 'e'\n",
    "\n",
    "e.zero_grad()\n",
    "e.backward()\n",
    "print('modified data on e:', e.data)\n",
    "build_graph(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe856d6-fa03-428d-9de1-68d63064d434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = sum([Value(2), 5, 6, 7])\n",
    "z.zero_grad()\n",
    "z.backward()\n",
    "build_graph(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c3245-a3b8-41ad-b297-0be21549345a",
   "metadata": {},
   "source": [
    "## A Multilayer Perceptron\n",
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9099a-afc9-4427-9cea-f2b70c70de1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \"\"\"\n",
    "    Neuron.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_inputs: int, activation: str = 'tanh'):\n",
    "        self.weights = [Value(random.uniform(-1, 1), name=f'w_{i}') for i in range(n_inputs)]\n",
    "        self.bias = Value(random.uniform(-1, 1), 'b')\n",
    "        self.activation = activation\n",
    "        \n",
    "    def __call__(self, x: list):\n",
    "        if len(x) != len(self.weights):\n",
    "            raise ValueError('Input should have the same size of weights')\n",
    "        z = sum([w * i for w, i in zip(self.weights, x)]) + self.bias\n",
    "        if self.activation == 'relu':\n",
    "            out = z.relu()\n",
    "        elif self.activation == 'tanh':\n",
    "            out = z.tanh()\n",
    "        else:\n",
    "            raise ValueError(f'Wrong activation type: {self.activation}')\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.weights + [self.bias]\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    Fully connected layer of neurons.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_inputs: int, n_outputs: int):\n",
    "        self.neurons = [Neuron(n_inputs) for _ in range(n_outputs)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "    \n",
    "    def parameters(self):\n",
    "        p = []\n",
    "        for n in self.neurons:\n",
    "            p.extend(n.parameters())\n",
    "        return p\n",
    "    \n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    Multilayer perceptron.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_inputs: int, layer_sizes: list):\n",
    "        self.sizes = [n_inputs] + layer_sizes\n",
    "        self.layers = [Layer(_i, _o) for _i, _o in zip(self.sizes, self.sizes[1:])]\n",
    "                       \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        p = []\n",
    "        for l in self.layers:\n",
    "            p.extend(l.parameters())\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8031f2a-ed01-4285-916e-19993bd9eae6",
   "metadata": {},
   "source": [
    "### Check components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60967e1-47a4-49f1-b1cd-44e659866353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee15b5-5395-493b-b0ab-584436dd25bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = Neuron(2)  # a neuron with two inputs\n",
    "o = n([Value(x_i, name=f'x_{i}')\n",
    "       for i, x_i\n",
    "       in enumerate([1, 3])])\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a93b7b-bd4b-4217-ab5d-e0eb027714f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = Layer(2, 3)  # a layer with 3 neurons of input size 2\n",
    "o = l([Value(x_i, name=f'x_{i}')\n",
    "       for i, x_i\n",
    "       in enumerate([1, 3])])\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b271f599-ff76-4cbf-a436-afeaa1acc4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = MLP(3, [4, 4, 1])  # an MLP with 3 and 2 neurons. input size 2\n",
    "o = m([Value(x_i, name=f'x_{i}')\n",
    "       for i, x_i\n",
    "       in enumerate([1, 2, 3])])\n",
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5619e23-66b0-4b70-b606-83fb0e19c25b",
   "metadata": {},
   "source": [
    "### Network in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352ba43-c03c-4dcd-ad21-008aaad17166",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d22777-6053-44ae-aa4e-e8e810c4d460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2, 3, -1],\n",
    "    [3, -1, 0.5],\n",
    "    [0.5, 1, 1],\n",
    "]\n",
    "ys = [1, -1, -1]\n",
    "\n",
    "# predictions\n",
    "y_pred = [m(x) for x in xs]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0d1ff-8bae-4757-a744-c242a8af62eb",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2bfa5f-a3a9-494d-afb0-14bbf6c486df",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MLP(3, [4, 4, 1])  # an MLP with 3 and 2 neurons. input size 2\n",
    "# build_graph(m([0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20662f6-3029-45e5-b9c5-a1622592388d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(m.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a88f7-995c-4dda-806c-1411a5669e8e",
   "metadata": {},
   "source": [
    "#### Training using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c38e2-7fb4-4574-894e-ecec59622c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 100000\n",
    "lr = 0.001\n",
    "for epoch in range(n_epochs):\n",
    "    # forward\n",
    "    ys_pred = [m(x) for x in xs]\n",
    "    L = sum((y - yp)**2 for y, yp in zip(ys, ys_pred)) / len(ys)  # MSE\n",
    "    if epoch % 2000 == 0:\n",
    "        print(f'epoch: {epoch}, loss: {L.data}')\n",
    "        \n",
    "    # backward\n",
    "    L.zero_grad()\n",
    "    L.backward()\n",
    "    \n",
    "    # update\n",
    "    for p in m.parameters():\n",
    "        p.data += -1 * lr * p.grad\n",
    "    \n",
    "print('Predictions:', [m(x) for x in xs])\n",
    "print('Targets:', ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
